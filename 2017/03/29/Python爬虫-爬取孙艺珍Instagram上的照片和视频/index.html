<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python爬虫--爬取孙艺珍Instagram上的照片和视频 | Htxf-fxtH</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. 需求爬取到孙艺珍Instagram上的所有照片和视频。
2. 解决过程阶段1先打开网页，OBOB。
该页面初始时只显示12张照片，通过点击”更多“按钮，屏幕一直往下滚动，会显示更多，直到显示出所有的照片和视频。在此过程中，该网页并没有重新加载。所以新显示出来的照片和视频是通过Ajax技术从服务器获取到的。
之前理解的爬虫一直是找HTML文件中的某些内容，并且根据某些规则不停地更新需要请求的网">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫--爬取孙艺珍Instagram上的照片和视频">
<meta property="og:url" content="http://yoursite.com/2017/03/29/Python爬虫-爬取孙艺珍Instagram上的照片和视频/index.html">
<meta property="og:site_name" content="Htxf-fxtH">
<meta property="og:description" content="1. 需求爬取到孙艺珍Instagram上的所有照片和视频。
2. 解决过程阶段1先打开网页，OBOB。
该页面初始时只显示12张照片，通过点击”更多“按钮，屏幕一直往下滚动，会显示更多，直到显示出所有的照片和视频。在此过程中，该网页并没有重新加载。所以新显示出来的照片和视频是通过Ajax技术从服务器获取到的。
之前理解的爬虫一直是找HTML文件中的某些内容，并且根据某些规则不停地更新需要请求的网">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\response.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\response preview.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 1.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 2.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 3.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\second query.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\first query end_cursor.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\video_url.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\video_query.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\crawler_result.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\download_result.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\images.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\videos.PNG">
<meta property="og:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\download_new_result.PNG">
<meta property="og:updated_time" content="2017-03-29T14:02:29.039Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫--爬取孙艺珍Instagram上的照片和视频">
<meta name="twitter:description" content="1. 需求爬取到孙艺珍Instagram上的所有照片和视频。
2. 解决过程阶段1先打开网页，OBOB。
该页面初始时只显示12张照片，通过点击”更多“按钮，屏幕一直往下滚动，会显示更多，直到显示出所有的照片和视频。在此过程中，该网页并没有重新加载。所以新显示出来的照片和视频是通过Ajax技术从服务器获取到的。
之前理解的爬虫一直是找HTML文件中的某些内容，并且根据某些规则不停地更新需要请求的网">
<meta name="twitter:image" content="http://yoursite.com/..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query.PNG">
  
    <link rel="alternative" href="/atom.xml" title="Htxf-fxtH" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open+Sans|">
  <link href='https://fonts.googleapis.com/css?family=Dancing+Script' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/style.css">
  

  <link rel="stylesheet" href="/css/base.css">
  <link rel="stylesheet" href="/css/home.css">
  <link rel="stylesheet" href="/css/animate.css">
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script type="text/javascript" src="http://code.jQuery.com/jquery-latest.js"></script>
  <script src="/js/base.js"></script>
  <script src="/js/jquery.cookie.js"></script>
  <script src="/fancybox/jquery.fancybox.js"></script>
  <script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>



<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
    <div id="insert" class="home_logo"></div>
    <div class="hamburger animated shake">
      <i ></i>
      <ul>
        <li class="home"><a href="/">Home<span></span></a></li>
        <li><a href="http://cpbxx.lofter.com/" target="blank">Works<span></span></a></li>
        <li class="home_notes_showon" ><a href="/">Notes<span></span></a></li>
        <li><a href="./tucaos.html">Tucaos<span></span></a></li>
      </ul>
    </div>
</header>

      <div class="outer">
        <section id="main"><div class="main_center"><article id="post-Python爬虫-爬取孙艺珍Instagram上的照片和视频" class="article article-type-post" itemscope itemprop="blogPost">

  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫--爬取孙艺珍Instagram上的照片和视频
    </h1>
  


        <div class="article-meta">
          <span class="article-date">
  <time datetime="2017-03-29T07:01:43.000Z" itemprop="datePublished">Mar 29 2017</time>
</span>

        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-需求"><a href="#1-需求" class="headerlink" title="1. 需求"></a>1. 需求</h3><p>爬取到<a href="https://www.instagram.com/yejinhand/" target="_blank" rel="external">孙艺珍Instagram</a>上的所有照片和视频。</p>
<h3 id="2-解决过程"><a href="#2-解决过程" class="headerlink" title="2. 解决过程"></a>2. 解决过程</h3><h4 id="阶段1"><a href="#阶段1" class="headerlink" title="阶段1"></a>阶段1</h4><p>先打开网页，OBOB。</p>
<p>该页面初始时只显示12张照片，通过点击”更多“按钮，屏幕一直往下滚动，会显示更多，直到显示出所有的照片和视频。在此过程中，该网页并没有重新加载。所以新显示出来的照片和视频是通过Ajax技术从服务器获取到的。</p>
<p>之前理解的爬虫一直是找HTML文件中的某些内容，并且根据某些规则不停地更新需要请求的网页列表，这样就不断的有新的HTML文件。</p>
<p>针对现在这种情况。会有两种解决方案？一种是在代码中模拟屏幕滚动，将所有内容都显示出来后，爬下整个HTML，从中找到照片和视频的url（或者边滚动边查找）；另一种是直接去找<strong>XHR</strong>（XmlHttpRequest对象），其中肯定存有照片和视频的url信息。</p>
<a id="more"></a>
<h4 id="阶段2"><a href="#阶段2" class="headerlink" title="阶段2"></a>阶段2</h4><p>通过Chrome调试工具查找请求url、图片和视频地址的存储模式。</p>
<p>先调出调试工具，再刷新一下页面。在Network下选中XHR，发现有些文件。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query.PNG" width="70%" height="70%"></p>
<p>发现其中query文件中有所需的东西。它放回的响应是一段json文件，通过调试工具提供的Preview可以方便的找到12张照片的url在nodes的12个对象中。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\response.PNG" width="70%" height="70%"></p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\response preview.PNG" width="70%" height="70%"></p>
<p>再仔细OB它的headers。调试工具帮忙将其分为了General、Response Headers、Request Headers和Form Data四个部分。从General中可以找到请求的url是h ttps://www.instagram.com/query/（h后空了个格，否则被解析成链接？？），请求的方法是POST，由于需要翻个墙，所以Remote Address是127.0.0.1:1080（这块儿还不清楚为什么）。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 1.PNG" width="70%" height="70%"></p>
<p>再看Request Heasers中，有个特殊的（其他网站不一定有的），x-csrftoken。这应该是关于<strong>CSRF</strong>(Cross-Site Request Forgery)跨站点伪造相关的设置？？？</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 2.PNG" width="70%" height="70%"></p>
<p>最后，还有一些Form Data。开始时不知道是做什么的。后来发现，加载更多数据，有一个新的query文件时，ig_user(1584172338)以及query_id:17849115430193904总是不变的。而第二个query中Form Data中的media.after(1407791225863562766, 12)，1407791225863562766正是上一个query中返回数据的page_info中的end_cursor的值。所以根据这块儿信息可以循环去请求新的数据。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\query headers 3.PNG" width="70%" height="70%"></p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\second query.PNG" width="70%" height="70%"></p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\first query end_cursor.PNG" width="70%" height="70%"></p>
<h4 id="阶段3"><a href="#阶段3" class="headerlink" title="阶段3"></a>阶段3</h4><p>开始code。</p>
<p>使用requests库发送HTTP请求，使用json库解析返回的响应json数据。</p>
<h5 id="version2"><a href="#version2" class="headerlink" title="version2"></a>version2</h5><p>需要翻个墙。所以发送请求时要加上proxies，注意写法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"></div><div class="line">proxies = &#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:1080'</span>,</div><div class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:1080'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">r = requests.post(url, proxies=proxies)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># HTTP请求的状态码是403，对被请求页面的访问被禁止。</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># 应该是一个HTML页面。</span></div><div class="line"><span class="comment"># 其中有一句是 &lt;html lang="en" class="no-js lt-ie9 lt-ie8 lt-ie7 not-logged-in "&gt; &lt;![endif]--&gt;</span></div><div class="line"><span class="comment"># 怀疑是否是要先登录才可以访问？但是在网页上浏览时，即使不登录也不影响访问。</span></div></pre></td></tr></table></figure></p>
<p>先不管登不登录的问题，被禁止访问，感觉由于没有模仿浏览器的行为？</p>
<h5 id="version2-1"><a href="#version2-1" class="headerlink" title="version2"></a>version2</h5><p>加上headers。尤其是user-agent。但还是仿照上面调试工具显示的Request Headers，把许多字段都加上了，唯一没有加的是cookie，因为感觉太多了。。。不知道直接copy行不行，就先没有加。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'accept'</span>: <span class="string">'*/*'</span>,</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'content-length'</span>: <span class="string">'0'</span>,</div><div class="line">    <span class="string">'content-type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</div><div class="line">    <span class="string">'origin'</span>: <span class="string">'https://www.instagram.com'</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">'https://www.instagram.com/yejinhand/'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'2zFuqbJM0TfsMbQNdf9dvdmUPWKRvCWN'</span>,</div><div class="line">    <span class="string">'x-instagram-ajax'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'x-requested-with'</span>: <span class="string">'XMLHttpRequest'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">proxies = &#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:1080'</span>,</div><div class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:1080'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">r = requests.post(url, headers=headers, proxies=proxies)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># 403</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># 与version1返回的一样</span></div></pre></td></tr></table></figure></p>
<p>headers中的这些东西开始时都不知道是咩。只知道user-agent是表示，发送请求的是一个浏览器。而且开始时以为因为referer是h ttps://www.instagram.com/yejinhand/，所以会返回孙艺珍的Instagram的主页而不是其他人的主页。这些知识在第3部分再记录。</p>
<p>当时出现这个问题，在网上查了好多，应该是要设置cookie。有的是专门再设置一个cookie，但在<a href="http://stackoverflow.com/questions/34447091/python-post-requests-causing-403-error" target="_blank" rel="external">这里</a>找到了一个方法，将cookie直接写到headers中。</p>
<h5 id="version3"><a href="#version3" class="headerlink" title="version3"></a>version3</h5><p>Stackoverflow上Martin Konecny是说将Curl “Cookie”粘贴到headers中，不了解curl。但是我是直接copy调试工具中的cookie字段，然后粘贴到代码中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'从调试面板中直接粘贴过来'</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">'*/*'</span>,</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'content-length'</span>: <span class="string">'0'</span>,</div><div class="line">    <span class="string">'content-type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</div><div class="line">    <span class="string">'origin'</span>: <span class="string">'https://www.instagram.com'</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">'https://www.instagram.com/yejinhand/'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'2zFuqbJM0TfsMbQNdf9dvdmUPWKRvCWN'</span>,</div><div class="line">    <span class="string">'x-instagram-ajax'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'x-requested-with'</span>: <span class="string">'XMLHttpRequest'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">proxies = &#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:1080'</span>,</div><div class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:1080'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">r = requests.post(url, headers=headers, proxies=proxies)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># 400 服务器未能理解请求</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># &#123;"status": "fail", "message": "invalid parameters"&#125;</span></div></pre></td></tr></table></figure></p>
<p>这下没有被禁止！！！但是服务器未能理解请求。返回的信息是说无效的参数。就说明请求时应该传一些参数的。应该就是Form data中的内容。</p>
<h5 id="version4"><a href="#version4" class="headerlink" title="version4"></a>version4</h5><p>加上Form Data。</p>
<p>开始时不知道Form Data是干什么的，也不知道怎样发送这些Form Data。在Request的<a href="http://docs.python-requests.org/zh_CN/latest/user/quickstart.html" target="_blank" rel="external">文档</a>中找到了‘’更加复杂的 POST 请求‘’，其中有介绍:</p>
<blockquote>
<p>通常，你想要发送一些编码为表单形式的数据——非常像一个 HTML 表单。要实现这个，只需简单地传递一个字典给 data 参数。你的数据字典在发出请求时会自动编码为表单形式：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>payload = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.post(<span class="string">"http://httpbin.org/post"</span>, data=payload)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(r.text)</div><div class="line">&#123;</div><div class="line">  ...</div><div class="line">  <span class="string">"form"</span>: &#123;</div><div class="line">    <span class="string">"key2"</span>: <span class="string">"value2"</span>,</div><div class="line">    <span class="string">"key1"</span>: <span class="string">"value1"</span></div><div class="line">  &#125;,</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当时不知道Form Data并不是真正的表单数据，但翻译正好表单数据，感觉和这个介绍很类似。但是在调试面板中看到其Form Data那么麻烦，不知道怎样写。试了好几次才闹好。有三个字段：q、ref、query_id。其中q的值，ig_user()后是一个{}，其中有media.after()以及另一个{}，其中又有count、nodes、page_info，nodes中又有其他一些信息。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'从调试面板中直接粘贴过来'</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">'*/*'</span>,</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'content-length'</span>: <span class="string">'0'</span>,</div><div class="line">    <span class="string">'content-type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</div><div class="line">    <span class="string">'origin'</span>: <span class="string">'https://www.instagram.com'</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">'https://www.instagram.com/yejinhand/'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'2zFuqbJM0TfsMbQNdf9dvdmUPWKRvCWN'</span>,</div><div class="line">    <span class="string">'x-instagram-ajax'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'x-requested-with'</span>: <span class="string">'XMLHttpRequest'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">proxies = &#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:1080'</span>,</div><div class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:1080'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># 这儿的afeter后的数字是第一个query的end_cursor的值</span></div><div class="line">query_data = &#123;</div><div class="line">    <span class="string">'q'</span>: <span class="string">'ig_user(1584172338)&#123;media.after(1407791225863562766, 12)&#123;count,nodes&#123;__typename,caption,code,comments&#123;count&#125;,comments_disabled,date,dimensions&#123;height,width&#125;,display_src,id,is_video,likes&#123;count&#125;,owner&#123;id&#125;,thumbnail_src,video_views&#125;,page_info&#125;&#125;'</span>,</div><div class="line">    <span class="string">'ref'</span>: <span class="string">'users::show'</span>,</div><div class="line">    <span class="string">'query_id'</span>: <span class="string">'17849115430193904'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">r = requests.post(url, data=query_data, headers=headers, proxies=proxies)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># 200！！！</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># 返回的正是调试面板中的Response信息！！！</span></div></pre></td></tr></table></figure></p>
<p>这样就成了！之后用json库解析的到的响应，就能得到自己所需的图片、视频url以及下一个请求的query_data了（将media.after后的数字替换为这一页的end_cursor）。</p>
<p>后来发现，在Form Data中可以只写自己想要的数据，比如这里只需要media中的page_info、nodes中的displa_src、is_video、以及node的code（查找视频的url是需要）。所以可以将query_data写成<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">query_data = &#123;</div><div class="line">    <span class="string">'q'</span>: <span class="string">'ig_user(1584172338)&#123;media.after(1407791225863562766, 12)&#123;nodes&#123;code, display_src, is_video&#125;&#125;, page_info&#125;'</span>,</div><div class="line">     <span class="string">'ref'</span>: <span class="string">'users::show'</span>,</div><div class="line">     <span class="string">'query_id'</span>: <span class="string">'17849115430193904'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h5 id="version5"><a href="#version5" class="headerlink" title="version5"></a>version5</h5><p>其实写出version4之前，cookie处和query_data的内容始终写不对。而且一直以为是要登录后才可以请求到所有的数据。在网上找到说是request库中Session可以保存登录信息，但也不会写。。。直到找到了<a href="https://github.com/LevPasha/instabot.py" target="_blank" rel="external">这个</a>，功能很强，可以登录，可以根据用户、标签等进行爬虫等等。但我所需的只是其中很少的一部分，根据其登录模块，写了以下代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="comment"># 登录时发送请求的地址。 </span></div><div class="line"><span class="comment"># 怎样获取的？故意填错用户名和密码，调试工具中可以查看到。</span></div><div class="line">login_url = <span class="string">'https://www.instagram.com/accounts/login/ajax/'</span></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"><span class="comment"># 要先去访问一下这个，可以获取一些cookie的设置</span></div><div class="line">get_url = <span class="string">'https://www.instagram.com/'</span></div><div class="line">proxy = &#123;</div><div class="line">    <span class="string">"http"</span>: <span class="string">"http://127.0.0.1:1080"</span>,</div><div class="line">    <span class="string">"https"</span>: <span class="string">"https://127.0.0.1:1080"</span></div><div class="line">&#125;</div><div class="line">login_data = &#123;</div><div class="line">    <span class="string">'username'</span>: <span class="string">'用户名'</span>,</div><div class="line">    <span class="string">'password'</span>: <span class="string">'密码'</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># 先开启一个Session</span></div><div class="line">s = requests.Session()</div><div class="line"><span class="comment"># 更新了cookies，但很多字段都是空的。也不知道干什么的。</span></div><div class="line">s.cookies.update(&#123;<span class="string">'sessionid'</span>: <span class="string">''</span>, <span class="string">'mid'</span>: <span class="string">''</span>, <span class="string">'ig_pr'</span>: <span class="string">'1'</span>,</div><div class="line">                  <span class="string">'ig_vw'</span>: <span class="string">'1920'</span>, <span class="string">'csrftoken'</span>: <span class="string">''</span>,</div><div class="line">                  <span class="string">'s_network'</span>: <span class="string">''</span>, <span class="string">'ds_user_id'</span>: <span class="string">''</span>&#125;)</div><div class="line"><span class="comment"># 更新headers，基本和之前写的一样。</span></div><div class="line">s.headers.update(&#123;<span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</div><div class="line">                  <span class="string">'Accept-Language'</span>: <span class="string">'en-US,en;q=0.8'</span>,</div><div class="line">                  <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">                  <span class="string">'Content-Length'</span>: <span class="string">'0'</span>,</div><div class="line">                  <span class="string">'Host'</span>: <span class="string">'www.instagram.com'</span>,</div><div class="line">                  <span class="string">'Origin'</span>: <span class="string">'https://www.instagram.com'</span>,</div><div class="line">                  <span class="string">'Referer'</span>: <span class="string">'https://www.instagram.com/'</span>,</div><div class="line">                  <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36,(KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36'</span>,</div><div class="line">                  <span class="string">'X-Instagram-AJAX'</span>: <span class="string">'1'</span>,</div><div class="line">                  <span class="string">'X-Requested-With'</span>: <span class="string">'XMLHttpRequest'</span>,</div><div class="line">                  &#125;)</div><div class="line"><span class="comment"># 最开始先请求了一下官网</span></div><div class="line">r = s.get(get_url)</div><div class="line"><span class="comment"># 随即更新了headers中x-csrtoken！！！说明这个很重要！！！</span></div><div class="line"><span class="comment"># 而且是从cookies中取到csrftoken的值更新的headers中的值！！！</span></div><div class="line">s.headers.update(&#123;<span class="string">'X-CSRFToken'</span>: r.cookies[<span class="string">'csrftoken'</span>]&#125;)</div><div class="line"><span class="comment"># 小睡一下，防止请求过频繁？</span></div><div class="line">time.sleep(<span class="number">4</span> * random.random())</div><div class="line"><span class="comment"># 发送登录请求</span></div><div class="line">login = s.post(login_url, data=login_data, proxies=proxy, allow_redirects=<span class="keyword">True</span>)</div><div class="line"><span class="comment"># 登录成功后，又更新了headers中x-csrftoken的值，还是从cookies中取到同是</span></div><div class="line"><span class="comment"># csrftoken的值更新的！！！</span></div><div class="line">s.headers.update(&#123;<span class="string">'X-CSRFToken'</span>: login.cookies[<span class="string">'csrftoken'</span>]&#125;)</div><div class="line"><span class="comment"># 又小睡一下</span></div><div class="line">time.sleep(<span class="number">5</span> * random.random())</div><div class="line"><span class="comment"># Form Data和之前一样</span></div><div class="line">query_data = &#123;</div><div class="line">    <span class="string">'q'</span>: <span class="string">'ig_user(1584172338)&#123;media.after(1407791225863562766, 12)&#123;count,nodes&#123;__typename,caption,code,comments&#123;count&#125;,comments_disabled,date,dimensions&#123;height,width&#125;,display_src,id,is_video,likes&#123;count&#125;,owner&#123;id&#125;,thumbnail_src,video_views&#125;,page_info&#125;&#125;'</span>,</div><div class="line">    <span class="string">'ref'</span>: <span class="string">'users::show'</span>,</div><div class="line">    <span class="string">'query_id'</span>: <span class="string">'17849115430193904'</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># 发送查询数据的post请求</span></div><div class="line">r = s.post(url, data=query_data, proxies=proxy)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># 200！！！</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># 返回的正是调试面板中的Response信息！！！</span></div></pre></td></tr></table></figure></p>
<p>这样，应该是通过Seesion保存了登录的信息。但发现在初始化cookies时，就没有存什么东西，而在登录之后，只是根据返回的cookies中的csrftoken字段的值更新了发送请求headers中的x-csrftoken的值。所以将上边的初始更新cookies的代码删掉后也可以成功获取到所需json数据！！！</p>
<h5 id="version6"><a href="#version6" class="headerlink" title="version6"></a>version6</h5><p>同时，发现真正影响拒绝请求还是接受请求的地方在于请求的headers中的x-csrftoken的值和cookies中csrftoken字段要一致！！！所以version4的代码可以精简为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">'https://www.instagram.com/query/'</span></div><div class="line"></div><div class="line"><span class="comment"># 注意这儿的cookie和x-csrftoken！！！</span></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'csrftoken=2zFuqbJM0TfsMbQNdf9dvdmUPWKRvCWN'</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">'*/*'</span>,</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</div><div class="line">    <span class="string">'content-length'</span>: <span class="string">'0'</span>,</div><div class="line">    <span class="string">'content-type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</div><div class="line">    <span class="string">'origin'</span>: <span class="string">'https://www.instagram.com'</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">'https://www.instagram.com/yejinhand/'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'2zFuqbJM0TfsMbQNdf9dvdmUPWKRvCWN'</span>,</div><div class="line">    <span class="string">'x-instagram-ajax'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'x-requested-with'</span>: <span class="string">'XMLHttpRequest'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">proxies = &#123;</div><div class="line">    <span class="string">'http'</span>: <span class="string">'http://127.0.0.1:1080'</span>,</div><div class="line">    <span class="string">'https'</span>: <span class="string">'https://127.0.0.1:1080'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">query_data = &#123;</div><div class="line">    <span class="string">'q'</span>: <span class="string">'ig_user(1584172338)&#123;media.after(1407791225863562766, 12)&#123;nodes&#123;code, display_src, is_video&#125;&#125;, page_info&#125;'</span>,</div><div class="line">     <span class="string">'ref'</span>: <span class="string">'users::show'</span>,</div><div class="line">     <span class="string">'query_id'</span>: <span class="string">'17849115430193904'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># 这儿的afeter后的数字是第一个query的end_cursor的值</span></div><div class="line"></div><div class="line">r = requests.post(url, data=query_data, headers=headers, proxies=proxies)</div><div class="line"></div><div class="line">print(r.status_code) <span class="comment"># 200！！！</span></div><div class="line"></div><div class="line">print(r.text) <span class="comment"># 返回了所需的json数据！！！</span></div></pre></td></tr></table></figure></p>
<p>而且试了试，将x-csrftoken改成任意的字符，只要保证cookies中的crsftoken字段和headers中crsftoken的字段一致就可以！！！也不用必须是多少个字符！！！！<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 将headers改成这样是OK的</span></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'csrftoken=a'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'a'</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># 将headers改成这样也是OK的</span></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'csrftoken=asdfadsfs'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'asdfadsfs'</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># 将headers改成这样是不OK的</span></div><div class="line"><span class="comment"># 403 拒绝访问</span></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'cookie'</span>: <span class="string">'csrftoken=a'</span>,</div><div class="line">    <span class="string">'x-csrftoken'</span>: <span class="string">'aa'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>但这是为什么？？？还没有闹清楚。</p>
<h4 id="阶段4"><a href="#阶段4" class="headerlink" title="阶段4"></a>阶段4</h4><p>图片的url都能找到了，但是上边请求的url返回的数据中并没有视频的url，如果是个视频的话，只是其中is_video字段的值是true。</p>
<p>找到一个视频，点击播放。还是同阶段1一样，打开调试工具。发现点击一个视频时，有个请求发出去了。其返回的数据中就有视频的url。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\video_url.PNG" width="70%" height="70%"></p>
<p>再OB其请求的headers。发现其中一段字符正是该node的code，与页面请求返回的数据中node的code一致。</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\video_query.PNG" width="70%" height="70%"></p>
<p>所以有了找图片以及视频url的思路。还是不断的发送h ttps://www.instagram.com/query/ 请求，根据上一次返回的数据中的end_cursor更新每一次请求时的Form Data，每次大概返回12个node信息，根据其中is_video字段，若是图片，就提取其url，完成任务。若是视频，就提取其code，根据code构造另一个HTTP请求(类似上图所示的请求)，再在其返回数据中提取视频的url，完成任务。</p>
<h4 id="阶段5"><a href="#阶段5" class="headerlink" title="阶段5"></a>阶段5</h4><p>完成程序。模仿类似的爬虫，将爬到所有图片url和视频url存储到硬盘上的txt文件中。</p>
<p>先在硬盘上创建两个文件夹用来存放image.txt和video.txt；写了一个查找视频url的函数（就是根据video所在node的code构造一个HTTP请求，再解析其json数据响应，取到视频的url）；之后设置爬虫所需的url、headers、proxies、form data；新建两个空列表，用来存储图片和视频的url；之后打开本地的image.txt和video.txt，将其中已有的先加入这两个空列表（主要是为下一次运行做准备，不要找的重复了。但现在想来是没有必要的，反正总把会某个用户主页上的所有资源都再请求一遍……不过可以保存住他/她删除了的图片或视频。也不对，已经删除了，url也就不能用了吧……）；之后就是循环的去发送请求了，根据响应的page_info中的has_next_page来判断要不要跳出循环，在循环体内找到一个资源的url就加入相应的列表；最后把两个列表中的数据存储到硬盘上。</p>
<p>最后根据硬盘上的资源url去下载，写了两个Python脚本。（文件打开方式是wb，写入二进制）<br>一个是第一次下载images.txt和videos.txt中的链接。有可能很多条，中间可能发生崩溃，所以设置process_image和process_video来记录已经下载的个数；为了下一次只下载新增的url，设置了此次已下载的个数last_num。<br>另一个是下载新增的资源。新增的资源还是在imgages.txt和videos.txt中存着，并且是在最上。先读取上一次下载后的总个数，再根据此时imgages.txt和videos.txt中链接个数判断要下载哪些链接，完成后再更新last_num值。</p>
<p>还不太了解Python中的类、对象，所以就简单的写成了顺序执行的代码……而且为了保存下载进度，频繁的打开关闭文件，开销是不是很大？？但想不出其他的解决办法了？？还有一点，下载新的链接可以正确实现？？</p>
<p>爬取链接的结果ig_syz.py：</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\crawler_result.PNG" width="70%" height="70%"></p>
<p>第一次下载的结果download.py：</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\download_result.PNG" width="70%" height="70%"></p>
<p>图片和视频：</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\images.PNG" width="70%" height="70%"></p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\videos.PNG" width="70%" height="70%"></p>
<p>运行下载新的链接脚本的结果download_new.py：</p>
<p><img src="..\Python爬虫-爬取孙艺珍Instagram上的照片和视频\download_new_result.PNG" width="70%" height="70%"></p>
<p>具体代码挂在GitHub上，点<a href="https://github.com/htxf/ig_user_crawler" target="_blank" rel="external">这里</a>。</p>
<h3 id="3-基础知识"><a href="#3-基础知识" class="headerlink" title="3. 基础知识"></a>3. 基础知识</h3><p>需要的一些基础知识有HTTP请求（尤其是其中的headers）、Ajax技术、XmlHttpRequest对象、CSRF(Cross-Site Request Forgery)、JSON数据。</p>
<p>这些内容在《JS高程》有一些。下一篇博客再记录吧。</p>
<h3 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4. 参考资料"></a>4. 参考资料</h3><ul>
<li><a href="https://ask.hellobi.com/blog/shiwei/6597" target="_blank" rel="external">40行动态爬虫代码搞定N张高清无码壁纸下载</a></li>
<li><a href="http://docs.python-requests.org/zh_CN/latest/user/quickstart.html" target="_blank" rel="external">Requests 文档</a></li>
<li><a href="http://www.jianshu.com/p/c3dbf8294c33" target="_blank" rel="external">Python爬虫(二)–Coursera抓站小结</a></li>
<li><a href="http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p02_read-write_json_data.html" target="_blank" rel="external">读写JSON数据</a></li>
<li><a href="http://www.hackcv.com/index.php/archives/41/" target="_blank" rel="external">使用requests下载图片的简单小测试</a></li>
<li><a href="http://www.imooc.com/video/10674" target="_blank" rel="external">慕课网 Python开发简单爬虫</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python-爬虫/">python 爬虫</a></li></ul>


    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2017/03/13/JS高程（七）/" id="article-nav-older" class="article-nav-link-wrap">ALI</a>
  
</nav>


  
</article>


</div>
</section>
      </div>
    </div>
  </div>
</body>
</html>
